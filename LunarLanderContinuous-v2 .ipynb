{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LunarLanderContinuous-v2 .ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cFa3w8eh06Aa","colab_type":"text"},"source":["#導入Tensorflow 2.0"]},{"cell_type":"code","metadata":{"id":"FISz65ljz_zG","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2.0.0-beta > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6dJxWAh1CtJ","colab_type":"text"},"source":["#導入Box.2D相關套件"]},{"cell_type":"code","metadata":{"id":"Ad9q94jE86_r","colab_type":"code","outputId":"6b72f5ef-6d5a-44a0-f4d2-7503585de1ed","executionInfo":{"status":"ok","timestamp":1579061658499,"user_tz":-480,"elapsed":6812,"user":{"displayName":"林奕銜","photoUrl":"","userId":"03571353073071135807"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["pip install -i https://pypi.tuna.tsinghua.edu.cn/simple box2d-py"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ktZ7wKBFjAwe","colab_type":"code","outputId":"98f2f230-15dd-4fa9-a902-c5061be46e14","executionInfo":{"status":"ok","timestamp":1579061668861,"user_tz":-480,"elapsed":17139,"user":{"displayName":"林奕銜","photoUrl":"","userId":"03571353073071135807"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["!apt-get install xvfb\n","!pip install pyvirtualdisplay\n","!pip install Pillow\n","!pip install 'gym[box2d]'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.3).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.5)\n","Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.9)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (6.2.2)\n","Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.6/dist-packages (0.15.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.4.1)\n","Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.12.0)\n","Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.3.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.17.5)\n","Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (2.3.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[box2d]) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Besm3B8_BYGV","colab_type":"code","outputId":"26b6eb9c-d0e5-40b9-c59f-11afbc903569","executionInfo":{"status":"ok","timestamp":1579061669520,"user_tz":-480,"elapsed":17763,"user":{"displayName":"林奕銜","photoUrl":"","userId":"03571353073071135807"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"J7VZ_Dfm1OPt","colab_type":"text"},"source":["#導入相關函式庫"]},{"cell_type":"code","metadata":{"id":"ysg4YOrT1NZO","colab_type":"code","outputId":"fa2883be-4361-4b95-9073-297c760c6e89","executionInfo":{"status":"ok","timestamp":1579061670162,"user_tz":-480,"elapsed":18394,"user":{"displayName":"林奕銜","photoUrl":"","userId":"03571353073071135807"}},"colab":{"base_uri":"https://localhost:8080/","height":440}},"source":["import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(40) #error only\n","import tensorflow.compat.v2 as tf\n","import random\n","import numpy as np\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"PPhh-fPPJsjW","colab_type":"text"},"source":["#Import Video"]},{"cell_type":"code","metadata":{"id":"p2OyJXTKHQo3","colab_type":"code","colab":{}},"source":["import glob\n","from gym.wrappers import Monitor\n","import io\n","import base64\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","  env = Monitor(env, './video', force=True)\n","  return env"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Os9nxG4vKHl5","colab_type":"text"},"source":["#Main_採用隨機動作"]},{"cell_type":"code","metadata":{"id":"wzCOb-nRHTzX","colab_type":"code","colab":{}},"source":["import gym\n","import time\n","from IPython import display\n","from PIL import Image\n","\n","env = wrap_env(gym.make('LunarLanderContinuous-v2'))\n","env.reset()\n","\n","for episode in range(1):\n","  observation = env.reset()  \n","  for i in range(1000): \n","    action = env.action_space.sample()   # 从 action_space 随机采样一个动作\n","    observation, reward, done, info = env.step(action)   # 执行动作\n","    #print(f'Action {action} Reward {reward}')\n","            \n","    \n","    \n","    if done:\n","        break\n","        \n","env.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8HlHM1SXLuTF","colab_type":"text"},"source":["#Video_採用隨機動作"]},{"cell_type":"code","metadata":{"id":"rOCSG2lqKjPv","colab_type":"code","outputId":"49dd524d-382b-47aa-904e-9e8e4d3e5574","executionInfo":{"status":"ok","timestamp":1579061672447,"user_tz":-480,"elapsed":20645,"user":{"displayName":"林奕銜","photoUrl":"","userId":"03571353073071135807"}},"colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["show_video()"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ZthQv6oPAKih","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":963},"outputId":"84487000-6fbb-4c79-837c-643ac4a4e3e7"},"source":["import os\n","import sys\n","from time import time as timer\n","\n","import gym\n","import numpy as np\n","import numpy.random as rd\n","# from tqdm import trange\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# import torch.utils.data as data\n","\n","\"\"\"\n","2019-07-01 Zen4Jia1Hao2, GitHub: Yonv1943\n","2019-08-01 Delay DDPG\n","2019-10-10 spectral normalization (should not use soft_update with SN)\n","2019-11-12 spectral normalization (should not use batch normalization with SN)\n","2019_11_22 essay-0.0 yi4shi2\n","2019_12_12 get_eva_reward_batch\n","\"\"\"\n","\n","\n","class Arguments:\n","    env_name = \"LunarLanderContinuous-v2\"\n","    max_step = 2000  # max steps in one epoch\n","    max_epoch = 1000  # max num of train_epoch\n","\n","    '''device'''\n","    gpu_id = sys.argv[0][-4]\n","    mod_dir = 'SN_DDPG_%s' % gpu_id\n","    is_remove = True  # remove the pre-training data? (True, False, None:ask me)\n","    random_seed = 1943\n","\n","    '''training'''\n","    actor_dim = 2 ** 8  # the network width of actor_net\n","    critic_dim = int(actor_dim * 1.25)  # the network width of critic_net\n","    memories_size = int(2 ** 16)  # memories capacity (memories: replay buffer)\n","    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\n","\n","    update_gap = 2 ** 7  # update the target_net, delay update\n","    update_c = 2  # update times of A:C is update_a:update_c, update_a==1\n","\n","    gamma = 0.99  # discount factor of future rewards\n","    explore_noise = 0.3  # action = select_action(state) + noise, 'explore_noise': sigma of noise\n","    policy_noise = 0.6  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\n","\n","    def __init__(self):\n","        # 1397s 77e, 2423s 69e, 1691s 57e, 1228s 51e\n","        # 30000~40000t 50~70e\n","        self.env_name = \"LunarLanderContinuous-v2\"\n","        self.explore_noise = 0.3\n","        self.policy_noise = 0.6\n","\n","        # 1784s 93, 1580s 95e, 1978s 120e\n","        # 50000~65000t 120~140e\n","        # self.env_name = \"BipedalWalker-v2\"\n","        # self.explore_noise = 0.4\n","        # self.policy_noise = 0.8\n","\n","\n","def run_train():  # 2019-12-11 2044\n","    args = Arguments()\n","\n","    \"\"\"initialization\"\"\"\n","    gpu_id = args.gpu_id\n","    mod_dir = args.mod_dir\n","    actor_dim = args.actor_dim\n","    critic_dim = args.critic_dim\n","    memories_size = args.memories_size\n","    random_seed = args.random_seed\n","    is_remove = args.is_remove\n","    env_name = args.env_name\n","\n","    print('  GPUid: %s' % gpu_id)\n","    print('  Model: %s' % mod_dir)\n","    whether_remove_history(remove=is_remove, mod_dir=mod_dir)\n","\n","    '''init env'''\n","    env = wrap_env(gym.make('LunarLanderContinuous-v2'))\n","    env.reset()\n","    state_dim, action_dim, action_max, target_reward = get_env_info(env)\n","    eva_size = 100\n","\n","    '''init mod'''\n","    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)\n","    agent = AgentDelayDDPG(state_dim, action_dim, actor_dim, critic_dim)\n","    agent.load_model(mod_dir)\n","\n","    memories = Memories(memories_size, state_dim, action_dim)\n","    memories.load(mod_dir)\n","\n","    torch.set_num_threads(8)\n","    torch.set_default_dtype(torch.float32)\n","    torch.manual_seed(random_seed)\n","    np.random.seed(random_seed)\n","\n","    \"\"\"train loop\"\"\"\n","    max_epoch = args.max_epoch\n","    max_step = args.max_step\n","    explore_noise = args.explore_noise\n","    policy_noise = args.policy_noise\n","    batch_size = args.batch_size\n","    update_gap = args.update_gap\n","    update_c = args.update_c\n","    gamma = args.gamma\n","\n","    '''show and plot'''\n","    show_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\n","    smooth_kernel = 2 ** 3  # smooth the reward/loss curves\n","    recorders = list()  # recorders.append((eva_reward, epoch_reward, actor_loss, critic_loss))\n","    recorders1 = list()  # recorders1.append((eva_reward, eva_std, iter_num))\n","    env_list = [gym.make(env_name) for _ in range(eva_size)]\n","    global_iter_num = 0\n","\n","    start_time = show_time = timer()\n","    try:\n","        for epoch in range(max_epoch):\n","            epoch_reward, iter_num = agent.inactive_in_env(\n","                env, memories, max_step, explore_noise, action_max, )\n","\n","            actor_loss, critic_loss = agent.update_parameter(\n","                memories, iter_num, batch_size, policy_noise, update_gap, update_c, gamma, )\n","\n","            eva_reward = get_eva_reward(\n","                agent, env, max_step, action_max, target_reward, )\n","\n","            recorders.append((eva_reward, epoch_reward, actor_loss, critic_loss))\n","            global_iter_num += iter_num\n","\n","            if timer() - show_time > show_gap:\n","                rewards = np.array(recorders[-smooth_kernel:])[:, 0:2]\n","                smooth_eva_r, smooth_epoch_r = np.average(rewards, axis=0)\n","                print(\"{:4}F    eva_reward {:7.2f}    epoch_reward {:7.2f}    actor_loss {:6.2f}    critic_loss {:6.2f}\".format(\n","                    epoch, smooth_eva_r, smooth_epoch_r, actor_loss, critic_loss))\n","\n","                eva_reward, eva_std = get_eva_reward_batch(\n","                    agent, env_list, max_step, action_max)\n","\n","                recorders1.append((eva_reward, eva_std, global_iter_num, epoch))\n","                show_time = timer()  # reset show_time after get_eva_reward_batch !\n","\n","            if eva_reward >= target_reward:\n","                print(\"########## Solved! ###########\")\n","                print(\"{:4}    |EvaR {:7.2f}    |EpoR {:7.2f}    |A {:6.2f}    C {:6.2f}\".format(\n","                    epoch, eva_reward, epoch_reward, actor_loss, critic_loss))\n","                break\n","\n","    except KeyboardInterrupt:\n","        print(\"KeyboardInterrupt\")\n","    print('TimeUsed:', int(timer() - start_time))\n","    agent.save_model(mod_dir)\n","    memories.save(mod_dir)\n","    np.save('%s/recorders.npy' % mod_dir, recorders)\n","    np.save('%s/recorders1.npy' % mod_dir, recorders1)\n","    print(\"Saved:\", mod_dir)\n","\n","    draw_plot(recorders, mod_dir, smooth_kernel)\n","\n","\n","def run_eval():  # 2019-12-11\n","    args = Arguments()\n","\n","    \"\"\"initialization\"\"\"\n","    gpu_id = args.gpu_id\n","    mod_dir = args.mod_dir\n","    env_name = args.env_name\n","    max_step = args.max_step\n","    actor_dim = args.actor_dim\n","\n","    '''init env'''\n","    env = wrap_env(gym.make('LunarLanderContinuous-v2'))\n","    env.reset()\n","    state_dim, action_dim, action_max, target_reward = get_env_info(env)\n","\n","    '''init mod'''\n","    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    act = Actor(state_dim, action_dim, actor_dim, device).to(device)\n","    act.load_state_dict(torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\n","    act.eval()\n","\n","    \"\"\"eval loop\"\"\"\n","    eval_epoch = 4  # reload and evaluate the target policy network(actor)\n","\n","    # import cv2\n","    t0 = timer()\n","    for epoch in range(eval_epoch):\n","        epoch_reward = 0\n","        state = env.reset()\n","        for iter_num in range(max_step):\n","            '''select_action'''\n","            state = torch.tensor((state,), dtype=torch.float32, device=device)\n","            action = act(state).cpu().data.numpy()[0]\n","\n","            state, reward, done, _ = env.step(action * action_max)\n","            epoch_reward += reward\n","\n","            env.render()\n","            # cv2.imwrite('%s/img_%4i.png'%(mod_dir, iter_num), env.render(mode='rgb_array'))\n","\n","            if done:\n","                break\n","\n","        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\n","    env.close()\n","    print(int(timer() - t0))\n","\n","\n","def run_test():  # 2019-12-12\n","    args = Arguments()\n","    mod_dir = args.mod_dir\n","\n","    load_path = '%s/recorders1.npy' % mod_dir\n","    recorders1 = np.load(load_path)\n","    print(recorders1.shape)\n","\n","    import matplotlib.pyplot as plt\n","\n","    fig, axs = plt.subplots(1)\n","\n","    '''sum_iter_nums'''\n","    # iter_nums = recorders1[:, 2]\n","    # sum_iter_nums = [iter_nums[0], ]\n","    # for iter_num in iter_nums[1:]:\n","    #     sum_iter_nums.append(sum_iter_nums[-1] + iter_num)\n","    sum_iter_nums = recorders1[:, 2]\n","\n","    rs_avg = recorders1[:, 0]\n","    rs_std_2 = recorders1[:, 1] / 2.0\n","    ax_color = 'royalblue'\n","    ax_label = 'Epoch R'\n","    axs.plot(sum_iter_nums, rs_avg, label=ax_label, color=ax_color)\n","    axs.fill_between(sum_iter_nums, rs_avg - rs_std_2, rs_avg + rs_std_2,\n","                     facecolor=ax_color, alpha=0.2, )\n","\n","    plt.savefig('{}/gloabal_iter_num.png'.format(mod_dir))\n","    plt.ion()\n","    plt.pause(4)\n","    # plt.show()\n","\n","\n","'''Network'''\n","\n","\n","class AgentDelayDDPG:\n","    def __init__(self, state_dim, action_dim, actor_dim, critic_dim):\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.device = device\n","\n","        '''dim and idx'''\n","        self.state_dim = state_dim\n","        self.action_dim = action_dim\n","        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\n","        self.action_idx = self.state_idx + action_dim\n","\n","        '''actor'''\n","        act = Actor(state_dim, action_dim, actor_dim, device).to(device)\n","        act.train()\n","        self.act = act\n","        self.act_optimizer = torch.optim.Adam(act.parameters(), lr=8e-4, betas=(0.5, 0.99))\n","\n","        act_target = Actor(state_dim, action_dim, actor_dim, device).to(device)\n","        act_target.eval()\n","        self.act_target = act_target\n","        self.act_target.load_state_dict(act.state_dict())\n","\n","        '''critic'''\n","        cri = Critic(state_dim, action_dim, critic_dim).to(device)\n","        cri.train()\n","        self.cri = cri\n","        self.cri_optimizer = torch.optim.Adam(cri.parameters(), lr=8e-4, betas=(0.5, 0.99))\n","\n","        cri_target = Critic(state_dim, action_dim, critic_dim).to(device)\n","        cri_target.eval()\n","        self.cri_target = cri_target\n","        self.cri_target.load_state_dict(cri.state_dict())\n","\n","        self.criterion = nn.SmoothL1Loss()\n","\n","        self.cri_update_counter = 0\n","        self.act_update_counter = 0\n","        self.actor_loss_avg = 0.0\n","        self.critic_loss_avg = 1.0\n","\n","    def select_action(self, state, explore_noise=0.0):\n","        state = torch.tensor((state,), dtype=torch.float32, device=self.device)\n","        action = self.act(state, explore_noise).cpu().data.numpy()\n","        return action[0]\n","\n","    @staticmethod\n","    def soft_update(target, source, tau=0.01):\n","        for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n","\n","    def inactive_in_env(self, env, memories, max_step, explore_noise, action_max):\n","        state = env.reset()\n","\n","        epoch_reward = 0\n","        iter_num = 0\n","\n","        self.act.eval()\n","        for iter_num in range(max_step):\n","            action = self.select_action(state, explore_noise)\n","\n","            next_state, reward, done, _ = env.step(action * action_max)\n","            memories.add(np.hstack((reward, 1 - float(done), state, action, next_state)))\n","            state = next_state\n","\n","            epoch_reward += reward\n","\n","            if done:\n","                break\n","        return epoch_reward, iter_num\n","\n","    def update_parameter(self, memories, iter_num, batch_size, policy_noise, update_gap,\n","                         update_c, gamma):  # 2019-12-11\n","        self.act_optimizer.param_groups[0]['lr'] = \\\n","            np.exp(-(self.critic_loss_avg / 4.0) ** 2) * 4e-4\n","        self.actor_loss_avg = self.critic_loss_avg = 0\n","\n","        k = 1 + memories.size / memories.memo_size\n","        iter_num = int(iter_num * k)\n","        batch_size = int(batch_size * k)\n","\n","        for i_act in range(iter_num):\n","            for i_cri in range(update_c):\n","                with torch.no_grad():\n","                    memory = memories.sample(batch_size)\n","                    memory = torch.tensor(memory, dtype=torch.float32, device=self.device)\n","\n","                    reward = memory[:, 0:1]\n","                    undone = memory[:, 1:2]\n","                    state = memory[:, 2:self.state_idx]\n","                    action = memory[:, self.state_idx:self.action_idx]\n","                    next_state = memory[:, self.action_idx:]\n","                    next_action = self.act_target(next_state, policy_noise)\n","\n","                    q_target = self.cri_target(next_state, next_action)\n","                    q_target = reward + undone * gamma * q_target\n","\n","                self.cri.train()\n","                q_eval = self.cri(state, action)\n","                critic_loss = self.criterion(q_eval, q_target)\n","                self.critic_loss_avg += critic_loss.item()\n","                self.cri_optimizer.zero_grad()\n","                critic_loss.backward()\n","                self.cri_optimizer.step()\n","\n","                self.cri_update_counter += 1\n","                if self.cri_update_counter == update_gap:\n","                    self.cri_update_counter = 0\n","\n","                    self.cri_target.load_state_dict(self.cri.state_dict())\n","                    # self.soft_update(self.cri_target, self.cri, tau=0.5)\n","\n","            self.cri.eval()\n","            actor_loss = -self.cri(state, self.act(state)).mean()\n","            self.actor_loss_avg += actor_loss.item()\n","            self.act_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.act_optimizer.step()\n","\n","            self.act_update_counter += 1\n","            if self.act_update_counter == update_gap:\n","                self.act_update_counter = 0\n","                self.act_target.load_state_dict(self.act.state_dict())\n","                # self.soft_update(self.act_target, self.act, tau=0.5)\n","                # self.soft_update(self.cri_target, self.cri)\n","\n","        self.actor_loss_avg /= iter_num\n","        self.critic_loss_avg /= iter_num * update_c\n","        return self.actor_loss_avg, self.critic_loss_avg\n","\n","    def save_model(self, mod_dir):\n","        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\n","        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\n","\n","        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\n","        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\n","        print(\"Saved act and cri:\", mod_dir)\n","\n","    def load_model(self, mod_dir):  # 2019-11-13\n","        print(\"Loading:\", mod_dir)\n","        if os.path.exists('%s/actor.pth' % (mod_dir,)):\n","            self.act.load_state_dict(\n","                torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\n","            self.act_target.load_state_dict(\n","                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\n","\n","            self.cri.load_state_dict(\n","                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\n","            self.cri_target.load_state_dict(\n","                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\n","        else:\n","            print(\"FileNotFound in mod_dir:%s\" % mod_dir)\n","\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, inp_dim, mid_dim, out_dim, sn=False):\n","        super(DenseNet, self).__init__()\n","        self.dense0 = nn.Linear(inp_dim * 1, mid_dim * 1)\n","        self.dense1 = nn.Linear(mid_dim * 1, mid_dim * 1)\n","        self.dense2 = nn.Linear(mid_dim * 2, mid_dim * 2)\n","\n","        self.dropout = nn.Dropout(p=0.25)\n","        self.dense_o = nn.Linear(mid_dim * 4, out_dim)\n","        if sn:\n","            self.dense_o = nn.utils.spectral_norm(self.dense_o)\n","\n","    def forward(self, x0):\n","        x1 = f_hard_swish(self.dense0(x0))\n","\n","        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\n","        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\n","\n","        self.dropout.p = rd.uniform(0.0, 0.25)\n","        x_o = self.dropout(x3)\n","        x_o = self.dense_o(x_o)\n","        return x_o\n","\n","\n","class Actor(nn.Module):\n","    def __init__(self, state_dim, action_dim, mid_dim, device):\n","        super(Actor, self).__init__()\n","        self.net = DenseNet(\n","            inp_dim=state_dim, mid_dim=mid_dim, out_dim=action_dim, sn=False)\n","        self.device = device\n","\n","    def forward(self, x, noise_std=0):\n","        a = self.net(x)\n","        a = torch.tanh(a)\n","\n","        if noise_std:\n","            with torch.no_grad():\n","                noise = torch.randn_like(a, device=self.device) * noise_std\n","                noise = torch.tanh(noise)\n","                a_temp = a + noise\n","                mask = ((-1.0 < a_temp) + (a_temp < 1.0)).type(torch.float32)\n","                noise *= mask\n","            a += noise\n","\n","        return a\n","\n","\n","class Critic(nn.Module):\n","    def __init__(self, state_dim, action_dim, mid_dim):\n","        super(Critic, self).__init__()\n","        self.net = DenseNet(\n","            inp_dim=state_dim + action_dim, mid_dim=mid_dim, out_dim=1, sn=True)\n","\n","    def forward(self, s, a):\n","        x = torch.cat((s, a), dim=1)\n","        x_o = self.net(x)\n","        return x_o\n","\n","\n","class Memories:\n","    def __init__(self, memo_size, state_dim, action_dim):\n","        self.ptr_u = 0  # pointer_for_update\n","        self.ptr_s = 0  # pointer_for_sample\n","        self.is_full = False\n","        self.size = 0\n","\n","        memo_size = int(memo_size)\n","        self.memo_size = memo_size\n","\n","        reward_dim = 1\n","        done_dim = 1\n","        slice_ids = [0, reward_dim, done_dim, state_dim, action_dim, state_dim]\n","        slice_ids = [sum(slice_ids[:i + 1]) for i in range(len(slice_ids))]\n","        self.slice_dim = slice_ids\n","\n","        memo_dim = slice_ids[-1]\n","        self.memories = np.empty((memo_size, memo_dim), dtype=np.float32)\n","        self.indices = np.arange(memo_size)\n","\n","    def add(self, memory):\n","        self.memories[self.ptr_u, :] = memory\n","\n","        self.ptr_u += 1\n","        if self.ptr_u == self.memo_size:\n","            self.ptr_u = 0\n","            if not self.is_full:\n","                self.is_full = True\n","                print('Memories is_full!')\n","        self.size = self.memo_size if self.is_full else self.ptr_u\n","\n","    def extend(self, memory):\n","        len_m = len(memory)\n","\n","        if self.ptr_u + len_m >= self.memo_size:\n","            len_m1 = self.memo_size - self.ptr_u\n","            len_m2 = len_m - len_m1\n","\n","            self.memories[self.ptr_u:, :] = memory[:len_m1]\n","            if len_m2:  # != 0\n","                self.memories[:len_m2, :] = memory[-len_m2:]\n","            self.ptr_u = len_m2\n","\n","            self.is_full = True\n","            print('Memories is_full!')\n","        else:\n","            _ptr_u = self.ptr_u\n","            self.ptr_u += len_m\n","\n","            self.memories[_ptr_u:self.ptr_u, :] = memory\n","\n","        self.size = self.memo_size if self.is_full else self.ptr_u\n","\n","    def sample(self, batch_size):\n","        self.ptr_s += batch_size\n","        if self.ptr_s >= self.size:\n","            self.ptr_s = batch_size\n","            rd.shuffle(self.indices[:self.size])\n","\n","        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\n","        return batch_memory\n","\n","    def save(self, mod_dir):\n","        ptr_u = self.memo_size if self.is_full else self.ptr_u\n","        save_path = \"%s/memories.npy\" % mod_dir\n","        np.save(save_path, self.memories[:ptr_u])\n","        print(\"Save memo:\", save_path)\n","\n","    def load(self, mod_dir):\n","        save_path = \"%s/memories.npy\" % mod_dir\n","        if os.path.exists(save_path):\n","            memories = np.load(save_path)\n","\n","            memo_len = memories.shape[0]\n","            if memo_len > self.memo_size:\n","                memo_len = self.memo_size\n","                self.ptr_u = self.memo_size\n","                print(\"Memories_num change:\", memo_len)\n","            else:\n","                self.ptr_u = memo_len\n","                self.size = memo_len\n","                print(\"Memories_num:\", self.ptr_u)\n","\n","            self.memories[:self.ptr_u] = memories[:memo_len]\n","            if self.ptr_u == self.memo_size:\n","                self.ptr_u = 0\n","                self.is_full = True\n","                print('Memories is_full!')\n","\n","            print(\"Load Memories:\", save_path)\n","        else:\n","            print(\"FileNotFound:\", save_path)\n","\n","\n","def f_hard_swish(x):\n","    return F.relu6(x + 3) / 6 * x\n","\n","\n","\"\"\"utils\"\"\"\n","\n","\n","def draw_plot(recorders, mod_dir, smooth_kernel):  # 2019-12-11\n","    load_path = '%s/recorders.npy' % mod_dir\n","    save_name = \"%s_plot.png\" % (mod_dir,)\n","\n","    \"\"\"compatibility\"\"\"\n","    if recorders is None:\n","        recorders = np.load(load_path)\n","        print(recorders.shape)\n","\n","    recorders = np.array(recorders)\n","\n","    if len(recorders) == 0:\n","        return print('Record is empty')\n","    else:\n","        print(\"Matplotlib Plot:\", save_name)\n","\n","    \"\"\"plot\"\"\"\n","    import matplotlib.pyplot as plt\n","    # plt.style.use('ggplot')\n","\n","    xs = np.arange(recorders.shape[0])\n","\n","    fig, axs = plt.subplots(2)\n","    plt.title(save_name, y=2.3)\n","\n","    ax11 = axs[0]\n","    ax11_color = 'lightcoral'\n","    ax11_label = 'Eval R'\n","    ax11.set_ylabel(ylabel=ax11_label, color=ax11_color)\n","    ax11.tick_params(axis='y', labelcolor=ax11_color)\n","    draw_smooth_plot(recorders[:, 0], smooth_kernel, ax11, ax11_color, ax11_label)\n","    # ax11.legend(loc='best')\n","    # ax11.set_facecolor('#f0f0f0')\n","    # ax11.grid(color='white', linewidth=1.5)\n","\n","    # ax12 = axs[0].twinx()\n","    ax12 = axs[0]\n","    ax12_color = 'royalblue'\n","    ax12_label = 'Epoch R'\n","    ax12.set_ylabel(ylabel=ax12_label, color=ax12_color)\n","    ax12.tick_params(axis='y', labelcolor=ax12_color)\n","    draw_smooth_plot(recorders[:, 1], smooth_kernel, ax12, ax12_color, ax12_label)\n","\n","    ax21 = axs[1]\n","    ax21_color = 'darkcyan'\n","    ax21_label = '- loss A'\n","    ax21.set_ylabel(ax21_label, color=ax21_color)\n","    ax21.plot(xs, -recorders[:, 2], label=ax21_label, color=ax21_color)  # negative loss A\n","    ax21.tick_params(axis='y', labelcolor=ax21_color)\n","\n","    ax22 = axs[1].twinx()\n","    ax22_color = 'darkcyan'\n","    ax22_label = 'loss C'\n","    ax22.set_ylabel(ax22_label, color=ax22_color)\n","    ax22.fill_between(xs, recorders[:, 3], facecolor=ax22_color, alpha=0.2, )\n","    ax22.tick_params(axis='y', labelcolor=ax22_color)\n","\n","    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\n","    # plt.show()\n","    plt.ion()\n","    plt.pause(4)\n","\n","\n","def draw_smooth_plot(y_reward, smooth_kernel, ax, ax_color, ax_label):\n","    r_avg = list()\n","    r_std = list()\n","    for i in range(len(y_reward)):\n","        i_beg = i - smooth_kernel // 2\n","        i_end = i_beg + smooth_kernel\n","\n","        i_beg = 0 if i_beg < 0 else i_beg\n","        rewards = y_reward[i_beg:i_end]\n","        r_avg.append(np.average(rewards))\n","        r_std.append(np.std(rewards))\n","    r_avg = np.array(r_avg)\n","    r_std = np.array(r_std)\n","\n","    xs = np.arange(y_reward.shape[0])\n","    ax.plot(xs, r_avg, label=ax_label, color=ax_color)\n","    ax.fill_between(xs, r_avg - r_std, r_avg + r_std, facecolor=ax_color, alpha=0.1, )\n","\n","\n","def get_env_info(env):  # 2019-11-06\n","    state_dim = env.observation_space.shape[0]\n","\n","    if isinstance(env.action_space, gym.spaces.Discrete):\n","        action_dim = env.action_space.n  # Discrete\n","        action_max = None\n","    elif isinstance(env.action_space, gym.spaces.Box):\n","        action_dim = env.action_space.shape[0]  # Continuous\n","        action_max = float(env.action_space.high[0])\n","    else:\n","        action_dim = None\n","        action_max = None\n","        print('! Error with env.action_space:', env.action_space)\n","        exit()\n","\n","    # state_dim = 14 ** 2  # For CarRacing-v0\n","\n","    target_reward = env.spec.reward_threshold\n","    if target_reward is None:\n","        print('! Error with target_reward:', target_reward)\n","        exit()\n","\n","    env_dict = {'env_name': repr(env)[10:-1],\n","                'state_dim': state_dim,\n","                'action_dim': action_dim,\n","                'action_max': (action_max, 'Discrete' if action_max is None else 'Continuous'),\n","                'target_reward': target_reward, }\n","    for key, value in env_dict.items():\n","        print(\"%16s\\t%s\" % (key, value))\n","    return state_dim, action_dim, action_max, target_reward\n","\n","\n","def get_eva_reward(agent, env, max_step, action_max, target_reward):  # 2019-12-12\n","    act = agent.act\n","    act.eval()\n","\n","    eva_epoch = 100\n","    eva_rewards = list()\n","    for eval_epoch in range(eva_epoch):\n","        state = env.reset()\n","\n","        eva_reward = 0\n","        for _ in range(max_step):\n","            action = agent.select_action(state)\n","            state, reward, done, _ = env.step(action * action_max)\n","\n","            eva_reward += reward\n","            if done:\n","                break\n","        eva_rewards.append(eva_reward)\n","\n","        # if fast_mode:\n","        temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\n","        if np.average(eva_rewards) < temp_target_reward:\n","            break  # break the evaluating loop ahead of time.\n","        if eval_epoch == 0 and eva_reward < target_reward:\n","            break\n","\n","    act.train()\n","\n","    eva_reward = np.average(eva_rewards)\n","    eva_r_std = float(np.std(eva_rewards))\n","    if eva_reward > target_reward:\n","        print(\"Eval| avg: %.2f std: %.2f\" % (eva_reward, eva_r_std))\n","\n","    return eva_reward\n","\n","\n","def get_eva_reward_batch(agent, env_list, max_step, action_max):  # 2019-12-12\n","    act = agent.act_target\n","    act.eval()\n","    device = agent.device\n","\n","    # assert isinstance(env_list, list)\n","    env_list = env_list.copy()\n","    eva_size = len(env_list)  # 100\n","\n","    epoch_rewards = list()\n","\n","    sum_rewards = [0, ] * eva_size\n","    states = [env.reset() for env in env_list]\n","\n","    for iter_num in range(max_step):\n","        states = torch.tensor(states, dtype=torch.float32, device=device)\n","        actions = act(states).cpu().data.numpy()\n","\n","        next_states = list()\n","        dones = list()\n","\n","        actions *= action_max\n","        for i in range(len(env_list) - 1, -1, -1):\n","            next_state, reward, done, _ = env_list[i].step(actions[i])\n","            next_states.insert(0, next_state)\n","            sum_rewards[i] += reward\n","            dones.insert(0, done)\n","            if done:\n","                epoch_rewards.append(sum_rewards[i])\n","                del sum_rewards[i]\n","                del env_list[i]\n","        states = next_states\n","\n","        if len(env_list) == 0:\n","            break\n","    act.train()\n","\n","    eva_reward = np.average(epoch_rewards)\n","    eva_r_std = float(np.std(epoch_rewards))\n","    return eva_reward, eva_r_std\n","\n","\n","def whether_remove_history(mod_dir, remove=None):\n","    if remove is None:\n","        remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\n","\n","    if remove:\n","        import shutil\n","        shutil.rmtree(mod_dir, ignore_errors=True)\n","        print(\"| Remove\")\n","        del shutil\n","\n","    if not os.path.exists(mod_dir):\n","        os.mkdir(mod_dir)\n","\n","\n","if __name__ == '__main__':\n","    run_train()\n","    # run_eval()\n","    run_test()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  GPUid: r\n","  Model: SN_DDPG_r\n","| Remove\n","        env_name\timeLimit<LunarLanderContinuous<LunarLanderContinuous-v2>>>\n","       state_dim\t8\n","      action_dim\t2\n","      action_max\t(1.0, 'Continuous')\n","   target_reward\t200\n","Loading: SN_DDPG_r\n","FileNotFound in mod_dir:SN_DDPG_r\n","FileNotFound: SN_DDPG_r/memories.npy\n","   2    eva_reward -633.21    epoch_reward -349.51    actor_loss   0.63    critic_loss   1.75\n","   4    eva_reward -498.80    epoch_reward -344.05    actor_loss   2.49    critic_loss   1.79\n","   5    eva_reward -431.91    epoch_reward -312.87    actor_loss  -1.73    critic_loss   1.35\n","   6    eva_reward -396.15    epoch_reward -282.32    actor_loss  -7.47    critic_loss   0.99\n","   7    eva_reward -354.27    epoch_reward -269.53    actor_loss -14.01    critic_loss   0.89\n","   8    eva_reward -235.76    epoch_reward -257.73    actor_loss -17.81    critic_loss   0.76\n","   9    eva_reward -200.17    epoch_reward -174.80    actor_loss -23.65    critic_loss   0.78\n","  10    eva_reward -150.94    epoch_reward -163.07    actor_loss -24.75    critic_loss   0.71\n","  11    eva_reward -129.30    epoch_reward -130.00    actor_loss -24.46    critic_loss   0.67\n","  12    eva_reward -129.78    epoch_reward -118.41    actor_loss -22.54    critic_loss   0.65\n","  13    eva_reward -127.19    epoch_reward -126.10    actor_loss -22.22    critic_loss   0.63\n","  14    eva_reward -121.75    epoch_reward -132.01    actor_loss -22.94    critic_loss   0.61\n","  15    eva_reward -118.95    epoch_reward -120.55    actor_loss -24.17    critic_loss   0.56\n","  16    eva_reward -115.26    epoch_reward  -94.37    actor_loss -24.65    critic_loss   0.64\n","  17    eva_reward -119.10    epoch_reward  -93.60    actor_loss -25.16    critic_loss   0.57\n","  18    eva_reward -122.11    epoch_reward  -87.78    actor_loss -23.01    critic_loss   0.54\n","  19    eva_reward  -99.70    epoch_reward -106.38    actor_loss -20.76    critic_loss   0.51\n","  20    eva_reward  -86.32    epoch_reward  -80.95    actor_loss -20.53    critic_loss   0.49\n","  21    eva_reward  -87.77    epoch_reward  -60.55    actor_loss -20.48    critic_loss   0.46\n","  22    eva_reward  -79.96    epoch_reward  -53.64    actor_loss -19.41    critic_loss   0.43\n","  23    eva_reward  -71.45    epoch_reward  -48.70    actor_loss -17.92    critic_loss   0.40\n","  24    eva_reward  -72.97    epoch_reward  -73.21    actor_loss -16.56    critic_loss   0.38\n","  25    eva_reward  -69.57    epoch_reward  -70.07    actor_loss -14.92    critic_loss   0.37\n","KeyboardInterrupt\n","TimeUsed: 8604\n","Saved act and cri: SN_DDPG_r\n","Save memo: SN_DDPG_r/memories.npy\n","Saved: SN_DDPG_r\n","Matplotlib Plot: SN_DDPG_r_plot.png\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAbIAAAESCAYAAACYb1DyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCpmIiISaCpmIiISaCpmIiITa/wBnR1f5P2VRMwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 3 Axes>"]},"metadata":{"tags":[]}}]}]}